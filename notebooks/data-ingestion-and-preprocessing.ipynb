{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17487406",
   "metadata": {},
   "source": [
    "# Create Refreshable Spark Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12650b6b",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04c486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NUCLEAR SPARK RESET - COMPLETE SYSTEM CLEANUP\n",
      "============================================================\n",
      "\n",
      "STEP 1: TERMINATING ALL JAVA PROCESSES\n",
      "----------------------------------------\n",
      "STATUS: All Java processes terminated\n",
      "\n",
      "STEP 2: CLEARING PYSPARK FROM MEMORY\n",
      "----------------------------------------\n",
      "STATUS: Removed 98 Spark-related modules from memory\n",
      "\n",
      "STEP 3: CONFIGURING CLEAN ENVIRONMENT\n",
      "----------------------------------------\n",
      "STATUS: Environment variables configured\n",
      "\n",
      "STEP 4: CREATING FRESH SPARK SESSION\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/11 17:09:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTS:\n",
      "----------------------------------------\n",
      "STATUS: Nuclear reset successful\n",
      "Spark UI: http://192.168.1.30:4040\n",
      "App ID: local-1754921377579\n",
      "============================================================\n",
      "SPARK SESSION READY FOR USE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Nuclear Spark Reset - Complete Clean Start\n",
    "# This completely wipes all Spark references and starts from scratch\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NUCLEAR SPARK RESET - COMPLETE SYSTEM CLEANUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Kill ALL Java processes (nuclear option)\n",
    "print(\"\\nSTEP 1: TERMINATING ALL JAVA PROCESSES\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    subprocess.run(['pkill', '-f', 'java'], capture_output=True)\n",
    "    time.sleep(5)  # Longer wait for complete cleanup\n",
    "    print(\"STATUS: All Java processes terminated\")\n",
    "except:\n",
    "    print(\"STATUS: Java process cleanup completed\")\n",
    "\n",
    "# Step 2: Clear ALL PySpark imports from memory\n",
    "print(\"\\nSTEP 2: CLEARING PYSPARK FROM MEMORY\")\n",
    "print(\"-\" * 40)\n",
    "modules_to_remove = []\n",
    "for module_name in sys.modules:\n",
    "    if 'pyspark' in module_name or 'py4j' in module_name:\n",
    "        modules_to_remove.append(module_name)\n",
    "\n",
    "for module_name in modules_to_remove:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "        \n",
    "print(f\"STATUS: Removed {len(modules_to_remove)} Spark-related modules from memory\")\n",
    "\n",
    "# Step 3: Set environment variables for clean start\n",
    "print(\"\\nSTEP 3: CONFIGURING CLEAN ENVIRONMENT\")\n",
    "print(\"-\" * 40)\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "print(\"STATUS: Environment variables configured\")\n",
    "\n",
    "# Step 4: Now import fresh PySpark and create session\n",
    "print(\"\\nSTEP 4: CREATING FRESH SPARK SESSION\")\n",
    "print(\"-\" * 40)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Create session with unique app name\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(f\"BerlinAirbnb_{int(time.time())}\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verify it works\n",
    "print(\"\\nRESULTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"STATUS: Nuclear reset successful\")\n",
    "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")\n",
    "print(f\"App ID: {spark.sparkContext.applicationId}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"SPARK SESSION READY FOR USE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8bc92",
   "metadata": {},
   "source": [
    "# Download Airbnb Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a7d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GETTING ALL BERLIN LINKS FROM INSIDE AIRBNB\n",
      "============================================================\n",
      "Looking for Berlin archived data button...\n",
      "Found 28 Berlin links:\n",
      "------------------------------------------------------------\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/data/calendar.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/data/listings.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/data/reviews.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/visualisations/listings.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/visualisations/neighbourhoods.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/visualisations/neighbourhoods.geojson\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-09-18/visualisations/reviews.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/data/calendar.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/data/listings.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/data/reviews.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/visualisations/listings.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/visualisations/neighbourhoods.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/visualisations/neighbourhoods.geojson\n",
      "https://data.insideairbnb.com/germany/be/berlin/2024-12-21/visualisations/reviews.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/data/calendar.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/data/listings.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/data/reviews.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/visualisations/listings.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/visualisations/neighbourhoods.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/visualisations/neighbourhoods.geojson\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-03-15/visualisations/reviews.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/data/calendar.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/data/listings.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/data/reviews.csv.gz\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/visualisations/listings.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/visualisations/neighbourhoods.csv\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/visualisations/neighbourhoods.geojson\n",
      "https://data.insideairbnb.com/germany/be/berlin/2025-06-20/visualisations/reviews.csv\n",
      "\n",
      "============================================================\n",
      "COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Get All Berlin Links (Including Archived Data)\n",
    "# Click \"show archived data\" and extract all Berlin links\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GETTING ALL BERLIN LINKS FROM INSIDE AIRBNB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    \n",
    "    # Set up headless Chrome\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(\"https://insideairbnb.com/get-the-data/\")\n",
    "    \n",
    "    print(\"Looking for Berlin archived data button...\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Click the specific Berlin archived data button\n",
    "    berlin_button = driver.find_element(By.CSS_SELECTOR, 'a.showArchivedData[data-city=\"Berlin\"]')\n",
    "    driver.execute_script(\"arguments[0].click();\", berlin_button)\n",
    "    time.sleep(3)  # Wait for content to load\n",
    "    \n",
    "    # Extract all Berlin links\n",
    "    page_source = driver.page_source\n",
    "    berlin_links = []\n",
    "    \n",
    "    # Find all URLs containing 'berlin'\n",
    "    berlin_patterns = [\n",
    "        r'https?://data\\.insideairbnb\\.com/germany/be/berlin/[^\\s<>\"\\']*'\n",
    "    ]\n",
    "    \n",
    "    for pattern in berlin_patterns:\n",
    "        matches = re.findall(pattern, page_source, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            if match not in berlin_links:\n",
    "                berlin_links.append(match)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    print(f\"Found {len(berlin_links)} Berlin links:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for link in sorted(berlin_links):\n",
    "        print(link)\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"ERROR: Selenium not installed. Install with: pip install selenium\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae5f4e",
   "metadata": {},
   "source": [
    "Select files of concern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51058788",
   "metadata": {},
   "source": [
    "# File Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ba41ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FILTERING FOR .CSV.GZ FILES ONLY\n",
      "============================================================\n",
      "Found 12 .csv.gz files:\n",
      "------------------------------------------------------------\n",
      "2024-09-18 - calendar.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2024-09-18/data/calendar.csv.gz\n",
      "2024-09-18 - listings.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2024-09-18/data/listings.csv.gz\n",
      "2024-09-18 - reviews.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2024-09-18/data/reviews.csv.gz\n",
      "2024-12-21 - calendar.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2024-12-21/data/calendar.csv.gz\n",
      "2024-12-21 - listings.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2024-12-21/data/listings.csv.gz\n",
      "2024-12-21 - reviews.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2024-12-21/data/reviews.csv.gz\n",
      "2025-03-15 - calendar.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2025-03-15/data/calendar.csv.gz\n",
      "2025-03-15 - listings.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2025-03-15/data/listings.csv.gz\n",
      "2025-03-15 - reviews.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2025-03-15/data/reviews.csv.gz\n",
      "2025-06-20 - calendar.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2025-06-20/data/calendar.csv.gz\n",
      "2025-06-20 - listings.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2025-06-20/data/listings.csv.gz\n",
      "2025-06-20 - reviews.csv.gz\n",
      "  https://data.insideairbnb.com/germany/be/berlin/2025-06-20/data/reviews.csv.gz\n",
      "\n",
      "============================================================\n",
      "CSV.GZ FILTERING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Filter Berlin Links - Only .csv.gz Files\n",
    "# Extract only the compressed data files for analysis\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FILTERING FOR .CSV.GZ FILES ONLY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Filter berlin_links from previous cell for .csv.gz files only\n",
    "try:\n",
    "    csv_gz_links = [link for link in berlin_links if link.endswith('.csv.gz')]\n",
    "    \n",
    "    print(f\"Found {len(csv_gz_links)} .csv.gz files:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for link in sorted(csv_gz_links):\n",
    "        # Extract filename and date for better readability\n",
    "        filename = link.split('/')[-1]\n",
    "        date = link.split('/')[-3] if len(link.split('/')) >= 3 else 'unknown'\n",
    "        print(f\"{date} - {filename}\")\n",
    "        print(f\"  {link}\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"ERROR: Run the previous cell first to get berlin_links\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CSV.GZ FILTERING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90c23b",
   "metadata": {},
   "source": [
    "# File Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa897be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DOWNLOADING .CSV.GZ FILES\n",
      "============================================================\n",
      "Downloading: 2025-06-20_listings.csv.gz\n",
      "✓ Downloaded: 2025-06-20_listings.csv.gz\n",
      "Downloading: 2025-06-20_calendar.csv.gz\n",
      "✓ Downloaded: 2025-06-20_calendar.csv.gz\n",
      "\n",
      "2 files downloaded successfully:\n",
      "  2025-06-20_listings.csv.gz: ../data/csv_gz_files/2025-06-20_listings.csv.gz\n",
      "  2025-06-20_calendar.csv.gz: ../data/csv_gz_files/2025-06-20_calendar.csv.gz\n",
      "\n",
      "============================================================\n",
      "DOWNLOAD COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Download CSV.GZ Files with Date Prefix\n",
    "# Download all .csv.gz files with proper error handling\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DOWNLOADING .CSV.GZ FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create download folder\n",
    "download_folder = \"../data/csv_gz_files\"\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# Dictionary to store downloaded files\n",
    "downloaded_files = {}\n",
    "\n",
    "# Download each file\n",
    "for link in csv_gz_links[:2]:\n",
    "    try:\n",
    "        # Extract date and filename\n",
    "        date = link.split('/')[-3]  # Extract date from URL\n",
    "        filename = link.split('/')[-1]  # Extract filename\n",
    "        new_filename = f\"{date}_{filename}\"  # Add date prefix\n",
    "        \n",
    "        print(f\"Downloading: {new_filename}\")\n",
    "        \n",
    "        # Download with error handling\n",
    "        response = requests.get(link, stream=True)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        \n",
    "        # Save file\n",
    "        file_path = os.path.join(download_folder, new_filename)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Add to dictionary\n",
    "        downloaded_files[new_filename] = file_path\n",
    "        \n",
    "        print(f\"✓ Downloaded: {new_filename}\")\n",
    "        time.sleep(5)  # Be polite to server\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"✗ Failed to download {link}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error with {link}: {e}\")\n",
    "\n",
    "print(f\"\\n{len(downloaded_files)} files downloaded successfully:\")\n",
    "for filename, path in downloaded_files.items():\n",
    "    print(f\"  {filename}: {path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOWNLOAD COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451ad1e",
   "metadata": {},
   "source": [
    "# UNZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eacfd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UNZIPPING CSV.GZ FILES\n",
      "============================================================\n",
      "Unzipping: 2025-06-20_listings.csv.gz → 2025-06-20_listings.csv\n",
      "✓ Unzipped: 2025-06-20_listings.csv\n",
      "Unzipping: 2025-06-20_calendar.csv.gz → 2025-06-20_calendar.csv\n",
      "✓ Unzipped: 2025-06-20_calendar.csv\n",
      "\n",
      "============================================================\n",
      "UNZIP COMPLETE FOR ['2025-06-20_listings.csv', '2025-06-20_calendar.csv']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Unzip CSV.GZ Files to Raw Data Folder\n",
    "# Extract all downloaded .csv.gz files\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UNZIPPING CSV.GZ FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create raw data folder\n",
    "raw_folder = \"../data/raw\"\n",
    "os.makedirs(raw_folder, exist_ok=True)\n",
    "\n",
    "# Dictionary to store unzipped files\n",
    "unzipped_files = {}\n",
    "\n",
    "# Unzip each file\n",
    "for filename, gz_path in downloaded_files.items():\n",
    "    try:\n",
    "        # Remove .gz extension for output filename\n",
    "        csv_filename = filename.replace('.gz', '')\n",
    "        csv_path = os.path.join(raw_folder, csv_filename)\n",
    "        \n",
    "        print(f\"Unzipping: {filename} → {csv_filename}\")\n",
    "        \n",
    "        # Unzip file\n",
    "        with gzip.open(gz_path, 'rb') as f_in:\n",
    "            with open(csv_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        unzipped_files[csv_filename] = csv_path\n",
    "        print(f\"✓ Unzipped: {csv_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to unzip {filename}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"UNZIP COMPLETE FOR {list(unzipped_files.keys())}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69aec2",
   "metadata": {},
   "source": [
    "# Data Loading - LISTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c1fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FETCHING FIRST LISTING CSV WITH SPARK (CORRECTED PARSING)\n",
      "============================================================\n",
      "Number of rows and columns in the listing DataFrame:\n",
      "Rows: 14187, Columns: 79\n",
      "============================================================\n",
      "All columns in the listing DataFrame:\n",
      "['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name', 'description', 'neighborhood_overview', 'picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'availability_eoy', 'number_of_reviews_ly', 'estimated_occupancy_l365d', 'estimated_revenue_l365d', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'license', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month']\n",
      "============================================================\n",
      "Data types of each column:\n",
      "[('id', 'bigint'), ('listing_url', 'string'), ('scrape_id', 'bigint'), ('last_scraped', 'date'), ('source', 'string'), ('name', 'string'), ('description', 'string'), ('neighborhood_overview', 'string'), ('picture_url', 'string'), ('host_id', 'int'), ('host_url', 'string'), ('host_name', 'string'), ('host_since', 'date'), ('host_location', 'string'), ('host_about', 'string'), ('host_response_time', 'string'), ('host_response_rate', 'string'), ('host_acceptance_rate', 'string'), ('host_is_superhost', 'string'), ('host_thumbnail_url', 'string'), ('host_picture_url', 'string'), ('host_neighbourhood', 'string'), ('host_listings_count', 'int'), ('host_total_listings_count', 'int'), ('host_verifications', 'string'), ('host_has_profile_pic', 'string'), ('host_identity_verified', 'string'), ('neighbourhood', 'string'), ('neighbourhood_cleansed', 'string'), ('neighbourhood_group_cleansed', 'string'), ('latitude', 'double'), ('longitude', 'double'), ('property_type', 'string'), ('room_type', 'string'), ('accommodates', 'int'), ('bathrooms', 'double'), ('bathrooms_text', 'string'), ('bedrooms', 'int'), ('beds', 'int'), ('amenities', 'string'), ('price', 'string'), ('minimum_nights', 'int'), ('maximum_nights', 'int'), ('minimum_minimum_nights', 'int'), ('maximum_minimum_nights', 'int'), ('minimum_maximum_nights', 'int'), ('maximum_maximum_nights', 'int'), ('minimum_nights_avg_ntm', 'double'), ('maximum_nights_avg_ntm', 'double'), ('calendar_updated', 'string'), ('has_availability', 'string'), ('availability_30', 'int'), ('availability_60', 'int'), ('availability_90', 'int'), ('availability_365', 'int'), ('calendar_last_scraped', 'date'), ('number_of_reviews', 'int'), ('number_of_reviews_ltm', 'int'), ('number_of_reviews_l30d', 'int'), ('availability_eoy', 'int'), ('number_of_reviews_ly', 'int'), ('estimated_occupancy_l365d', 'int'), ('estimated_revenue_l365d', 'int'), ('first_review', 'date'), ('last_review', 'date'), ('review_scores_rating', 'double'), ('review_scores_accuracy', 'double'), ('review_scores_cleanliness', 'double'), ('review_scores_checkin', 'double'), ('review_scores_communication', 'double'), ('review_scores_location', 'double'), ('review_scores_value', 'double'), ('license', 'string'), ('instant_bookable', 'string'), ('calculated_host_listings_count', 'int'), ('calculated_host_listings_count_entire_homes', 'int'), ('calculated_host_listings_count_private_rooms', 'int'), ('calculated_host_listings_count_shared_rooms', 'int'), ('reviews_per_month', 'double')]\n",
      "First 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/11 17:10:02 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------+------------+---------------+--------------------+--------------------+---------------------+--------------------+-------+--------------------+--------------+----------+--------------------+--------------------+------------------+------------------+--------------------+-----------------+--------------------+--------------------+------------------+-------------------+-------------------------+--------------------+--------------------+----------------------+---------------+----------------------+----------------------------+--------+---------+------------------+---------------+------------+---------+--------------+--------+----+--------------------+-------+--------------+--------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------+----------------+---------------+---------------+---------------+----------------+---------------------+-----------------+---------------------+----------------------+----------------+--------------------+-------------------------+-----------------------+------------+-----------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----------------+----------------+------------------------------+-------------------------------------------+--------------------------------------------+-------------------------------------------+-----------------+\n",
      "|   id|         listing_url|     scrape_id|last_scraped|         source|                name|         description|neighborhood_overview|         picture_url|host_id|            host_url|     host_name|host_since|       host_location|          host_about|host_response_time|host_response_rate|host_acceptance_rate|host_is_superhost|  host_thumbnail_url|    host_picture_url|host_neighbourhood|host_listings_count|host_total_listings_count|  host_verifications|host_has_profile_pic|host_identity_verified|  neighbourhood|neighbourhood_cleansed|neighbourhood_group_cleansed|latitude|longitude|     property_type|      room_type|accommodates|bathrooms|bathrooms_text|bedrooms|beds|           amenities|  price|minimum_nights|maximum_nights|minimum_minimum_nights|maximum_minimum_nights|minimum_maximum_nights|maximum_maximum_nights|minimum_nights_avg_ntm|maximum_nights_avg_ntm|calendar_updated|has_availability|availability_30|availability_60|availability_90|availability_365|calendar_last_scraped|number_of_reviews|number_of_reviews_ltm|number_of_reviews_l30d|availability_eoy|number_of_reviews_ly|estimated_occupancy_l365d|estimated_revenue_l365d|first_review|last_review|review_scores_rating|review_scores_accuracy|review_scores_cleanliness|review_scores_checkin|review_scores_communication|review_scores_location|review_scores_value|          license|instant_bookable|calculated_host_listings_count|calculated_host_listings_count_entire_homes|calculated_host_listings_count_private_rooms|calculated_host_listings_count_shared_rooms|reviews_per_month|\n",
      "+-----+--------------------+--------------+------------+---------------+--------------------+--------------------+---------------------+--------------------+-------+--------------------+--------------+----------+--------------------+--------------------+------------------+------------------+--------------------+-----------------+--------------------+--------------------+------------------+-------------------+-------------------------+--------------------+--------------------+----------------------+---------------+----------------------+----------------------------+--------+---------+------------------+---------------+------------+---------+--------------+--------+----+--------------------+-------+--------------+--------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------+----------------+---------------+---------------+---------------+----------------+---------------------+-----------------+---------------------+----------------------+----------------+--------------------+-------------------------+-----------------------+------------+-----------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----------------+----------------+------------------------------+-------------------------------------------+--------------------------------------------+-------------------------------------------+-----------------+\n",
      "| 3176|https://www.airbn...|20250620182343|  2025-06-21|    city scrape|Fabulous Flat in ...|This beautiful fi...| The neighbourhood...|https://a0.muscac...|   3718|https://www.airbn...|        Britta|2008-10-19| Coledale, Australia|We love to travel...|within a few hours|              100%|                 80%|                f|https://a0.muscac...|https://a0.muscac...|   Prenzlauer Berg|                  1|                        1|  ['email', 'phone']|                   t|                     t|Berlin, Germany|  Prenzlauer Berg S...|                      Pankow|52.53471|  13.4181|Entire rental unit|Entire home/apt|           2|      1.0|        1 bath|       1|   2|[\"Iron\", \"Cleanin...|$105.00|            63|           730|                    63|                    63|                   730|                   730|                  63.0|                 730.0|            NULL|               t|              0|              4|              4|             250|           2025-06-21|              149|                    1|                     0|              79|                   0|                      126|                  13230|  2009-06-20| 2025-03-02|                4.63|                  4.67|                     4.52|                 4.65|                        4.7|                  4.92|               4.61|             NULL|               f|                             1|                                          1|                                           0|                                          0|             0.76|\n",
      "| 9991|https://www.airbn...|20250620182343|  2025-06-21|    city scrape|Geourgeous flat -...|4 bedroom with ve...| Prenzlauer Berg i...|https://a0.muscac...|  33852|https://www.airbn...|       Philipp|2009-08-25|     Berlin, Germany|Born in Munich - ...|      within a day|               50%|                  0%|                f|https://a0.muscac...|https://a0.muscac...|   Prenzlauer Berg|                  1|                        1|  ['email', 'phone']|                   t|                     t|Berlin, Germany|  Prenzlauer Berg S...|                      Pankow|52.53269| 13.41805|Entire rental unit|Entire home/apt|           7|      2.5|     2.5 baths|       4|   4|[\"Iron\", \"Wifi\", ...|$135.00|             6|            14|                     6|                     6|                    14|                    14|                   6.0|                  14.0|            NULL|               t|              0|              0|              5|             193|           2025-06-21|                7|                    0|                     0|              29|                   0|                        0|                      0|  2015-08-09| 2020-01-04|                 5.0|                   5.0|                      5.0|                  5.0|                        5.0|                  4.86|               4.86|03/Z/RA/003410-18|               f|                             1|                                          1|                                           0|                                          0|             0.06|\n",
      "|14325|https://www.airbn...|20250620182343|  2025-06-21|    city scrape|Studio Apartment ...|The apartment is ...|                 NULL|https://a0.muscac...|  55531|https://www.airbn...|Chris + Oliver|2009-11-18|     Berlin, Germany|From Berlin, Germ...|      within a day|              100%|                 25%|                t|https://a0.muscac...|https://a0.muscac...|   Prenzlauer Berg|                  4|                        5|['email', 'phone'...|                   t|                     t|           NULL|  Prenzlauer Berg N...|                      Pankow|52.54813| 13.40366|Entire rental unit|Entire home/apt|           1|      1.0|        1 bath|       0|   1|[\"Hangers\", \"Wifi...| $75.00|           150|          1125|                   150|                   150|                  1125|                  1125|                 150.0|                1125.0|            NULL|               t|              0|              0|              0|             262|           2025-06-21|               26|                    0|                     0|              91|                   0|                        0|                      0|  2010-06-29| 2023-11-30|                4.68|                   5.0|                     4.85|                  4.7|                       4.85|                   4.6|               4.45|             NULL|               f|                             4|                                          4|                                           0|                                          0|             0.14|\n",
      "|16644|https://www.airbn...|20250620182343|  2025-06-21|previous scrape|In the Heart of B...|Light and sunny 2...| Our Part of Kreuz...|https://a0.muscac...|  64696|https://www.airbn...|          Rene|2009-12-20|      Santa Cruz, CA|Friendly and soci...|within a few hours|              100%|                  0%|                f|https://a0.muscac...|https://a0.muscac...|         Kreuzberg|                  4|                        4|           ['phone']|                   t|                     t|Berlin, Germany|  nördliche Luisens...|        Friedrichshain-Kr...|52.50312| 13.43508|      Entire condo|Entire home/apt|           4|     NULL|        1 bath|       1|NULL|[\"Iron\", \"Hangers...|   NULL|            93|           365|                    93|                    93|                   365|                   365|                  93.0|                 365.0|            NULL|               t|              0|              0|              0|               0|           2025-06-21|               48|                    0|                     0|               0|                   0|                        0|                   NULL|  2010-06-04| 2017-12-14|                4.72|                  4.86|                     4.86|                 4.93|                       4.86|                  4.67|               4.71|             NULL|               f|                             2|                                          2|                                           0|                                          0|             0.26|\n",
      "|17904|https://www.airbn...|20250620182343|  2025-06-21|    city scrape|Beautiful Kreuzbe...|- apt is availabl...| The apartment is ...|https://a0.muscac...|  68997|https://www.airbn...|      Matthias|2010-01-08|Rio de Janeiro, B...|I  am a  journali...|    within an hour|              100%|                 94%|                f|https://a0.muscac...|https://a0.muscac...|        Copacabana|                  2|                        5|  ['email', 'phone']|                   t|                     t|Berlin, Germany|          Reuterstraße|                    Neukölln|52.49419| 13.42166|Entire rental unit|Entire home/apt|           2|      1.0|        1 bath|       0|   1|[\"Iron\", \"Wifi\", ...| $28.00|            92|           365|                    92|                    92|                   365|                   365|                  92.0|                 365.0|            NULL|               t|              0|              0|             17|             111|           2025-06-21|              298|                    0|                     0|              29|                   0|                        0|                      0|  2010-02-18| 2022-12-01|                4.77|                  4.82|                     4.71|                 4.89|                       4.92|                  4.88|               4.65|             NULL|               f|                             1|                                          1|                                           0|                                          0|              1.6|\n",
      "+-----+--------------------+--------------+------------+---------------+--------------------+--------------------+---------------------+--------------------+-------+--------------------+--------------+----------+--------------------+--------------------+------------------+------------------+--------------------+-----------------+--------------------+--------------------+------------------+-------------------+-------------------------+--------------------+--------------------+----------------------+---------------+----------------------+----------------------------+--------+---------+------------------+---------------+------------+---------+--------------+--------+----+--------------------+-------+--------------+--------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------+----------------+---------------+---------------+---------------+----------------+---------------------+-----------------+---------------------+----------------------+----------------+--------------------+-------------------------+-----------------------+------------+-----------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----------------+----------------+------------------------------+-------------------------------------------+--------------------------------------------+-------------------------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Fetch csv with name listing using spark with proper parsing\n",
    "from pyspark.sql import SparkSession\n",
    "print(\"=\" * 60)\n",
    "print(\"FETCHING FIRST LISTING CSV WITH SPARK (CORRECTED PARSING)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "listing_csv_path = unzipped_files[next((f for f in unzipped_files if \"listings\" in f), None)]\n",
    "\n",
    "# Read CSV with proper parsing options\n",
    "listing_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\", \"true\") \\\n",
    "    .option(\"ignoreTrailingWhiteSpace\", \"true\") \\\n",
    "    .csv(listing_csv_path)\n",
    "\n",
    "# Get all columns first (before using all_columns)\n",
    "all_columns = listing_df.columns\n",
    "\n",
    "# How many rows/columns \n",
    "print(\"Number of rows and columns in the listing DataFrame:\")\n",
    "num_rows = listing_df.count()\n",
    "num_columns = len(all_columns)\n",
    "print(f\"Rows: {num_rows}, Columns: {num_columns}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"All columns in the listing DataFrame:\")\n",
    "print(all_columns)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# print data types for all columns\n",
    "print(\"Data types of each column:\")\n",
    "print(listing_df.dtypes)\n",
    "\n",
    "# Show first 5 rows with limited columns to avoid display issues\n",
    "print(\"First 5 rows\")\n",
    "listing_df.show(5)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2d7de",
   "metadata": {},
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb4ec7",
   "metadata": {},
   "source": [
    "## Column Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum, when\n",
    "\n",
    "# Select comprehensive columns for analysis\n",
    "selected_columns = [\n",
    "    # Core identifiers and location\n",
    "    \"id\", \"host_id\", \"latitude\", \"longitude\",\n",
    "    \n",
    "    # Neighborhood data\n",
    "    \"neighbourhood_group_cleansed\",\n",
    "    \n",
    "    # Review and rating data\n",
    "    \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \n",
    "    \"review_scores_checkin\", \"review_scores_communication\", \"review_scores_location\", \n",
    "    \"review_scores_value\", \"reviews_per_month\", \"number_of_reviews\",\n",
    "    \n",
    "    # Pricing and availability\n",
    "    \"price\",\n",
    "    \n",
    "    # \"availability_30\", \"availability_60\", \"availability_90\", \"availability_365\",\n",
    "    \"minimum_nights\", \"maximum_nights\",\n",
    "    \n",
    "    # Property characteristics\n",
    "    \"property_type\", \"amenities\", \"accommodates\", \"beds\"\n",
    "]\n",
    "\n",
    "listing_df = listing_df.select(*selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06cd5b",
   "metadata": {},
   "source": [
    "## Non-null Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91d4756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows before filtering critical column: 14187\n",
      "Rows after filtering (no nulls in critical columns): 9183\n"
     ]
    }
   ],
   "source": [
    "# Filter to keep only rows where critical columns are not null\n",
    "critical_columns = [\"price\", \"latitude\", \"longitude\", \"neighbourhood_group_cleansed\"]\n",
    "\n",
    "print(f\"\\nRows before filtering critical column: {listing_df.count()}\")\n",
    "\n",
    "# Apply filter - keep rows where ALL critical columns are not null\n",
    "listing_df = listing_df.filter(\n",
    "    col(\"price\").isNotNull() \n",
    "    & ((col(\"latitude\").isNotNull() & col(\"longitude\").isNotNull()) \n",
    "        | col(\"neighbourhood_group_cleansed\").isNotNull())\n",
    ")\n",
    "\n",
    "print(f\"Rows after filtering (no nulls in critical columns): {listing_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d6e91",
   "metadata": {},
   "source": [
    "## Enforce Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18093c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENFORCING DATA TYPES\n",
      "============================================================\n",
      "Current schema:\n",
      "[('id', 'bigint'), ('host_id', 'int'), ('latitude', 'double'), ('longitude', 'double'), ('neighbourhood_group_cleansed', 'string'), ('review_scores_rating', 'double'), ('review_scores_accuracy', 'double'), ('review_scores_cleanliness', 'double'), ('review_scores_checkin', 'double'), ('review_scores_communication', 'double'), ('review_scores_location', 'double'), ('review_scores_value', 'double'), ('reviews_per_month', 'double'), ('number_of_reviews', 'int'), ('price', 'string'), ('minimum_nights', 'int'), ('maximum_nights', 'int'), ('property_type', 'string'), ('room_type', 'string'), ('amenities', 'string'), ('accommodates', 'int'), ('beds', 'int')]\n",
      "\n",
      "Schema after data type conversion:\n",
      "[('id', 'bigint'), ('host_id', 'bigint'), ('latitude', 'double'), ('longitude', 'double'), ('neighbourhood_group_cleansed', 'string'), ('review_scores_rating', 'float'), ('review_scores_accuracy', 'float'), ('review_scores_cleanliness', 'float'), ('review_scores_checkin', 'float'), ('review_scores_communication', 'float'), ('review_scores_location', 'float'), ('review_scores_value', 'float'), ('reviews_per_month', 'float'), ('number_of_reviews', 'int'), ('price', 'float'), ('minimum_nights', 'int'), ('maximum_nights', 'int'), ('property_type', 'string'), ('room_type', 'string'), ('amenities', 'string'), ('accommodates', 'int'), ('beds', 'int')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, FloatType, LongType \n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ENFORCING DATA TYPES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show current schema before conversion\n",
    "print(\"Current schema:\")\n",
    "print(listing_df.dtypes)\n",
    "\n",
    "# Clean price column first (remove $ and commas)\n",
    "listing_df = listing_df.withColumn(\"price\", regexp_replace(col(\"price\"), \"[\\$,]\", \"\"))\n",
    "\n",
    "# Inferred Schema\n",
    "# [('id', 'bigint'), ('host_id', 'int'), ('latitude', 'double'), ('longitude', 'double'), ('neighbourhood', 'string'), ('neighbourhood_group_cleansed', 'string'), ('review_scores_rating', 'double'), ('review_scores_accuracy', 'double'), ('review_scores_cleanliness', 'double'), ('review_scores_checkin', 'double'), ('review_scores_communication', 'double'), ('review_scores_location', 'double'), ('review_scores_value', 'double'), ('reviews_per_month', 'double'), ('number_of_reviews', 'int'), ('price', 'string'), ('availability_30', 'int'), ('availability_60', 'int'), ('availability_90', 'int'), ('availability_365', 'int'), ('minimum_nights', 'int'), ('maximum_nights', 'int'), ('property_type', 'string'), ('room_type', 'string'), ('amenities', 'string'), ('accommodates', 'int'), ('beds', 'int')]\n",
    "\n",
    "\n",
    "# Cast columns to appropriate data types\n",
    "listing_df = listing_df \\\n",
    "    .withColumn(\"id\", col(\"id\").cast(LongType())) \\\n",
    "    .withColumn(\"host_id\", col(\"host_id\").cast(LongType())) \\\n",
    "    .withColumn(\"latitude\", col(\"latitude\").cast(DoubleType())) \\\n",
    "    .withColumn(\"longitude\", col(\"longitude\").cast(DoubleType())) \\\n",
    "    .withColumn(\"neighbourhood_group_cleansed\", col(\"neighbourhood_group_cleansed\").cast(StringType())) \\\n",
    "    .withColumn(\"review_scores_rating\", col(\"review_scores_rating\").cast(FloatType())) \\\n",
    "    .withColumn(\"review_scores_accuracy\", col(\"review_scores_accuracy\").cast(FloatType())) \\\n",
    "    .withColumn(\"review_scores_cleanliness\", col(\"review_scores_cleanliness\").cast(FloatType())) \\\n",
    "    .withColumn(\"review_scores_checkin\", col(\"review_scores_checkin\").cast(FloatType())) \\\n",
    "    .withColumn(\"review_scores_communication\", col(\"review_scores_communication\").cast(FloatType())) \\\n",
    "    .withColumn(\"review_scores_location\", col(\"review_scores_location\").cast(FloatType())) \\\n",
    "    .withColumn(\"review_scores_value\", col(\"review_scores_value\").cast(FloatType())) \\\n",
    "    .withColumn(\"reviews_per_month\", col(\"reviews_per_month\").cast(FloatType())) \\\n",
    "    .withColumn(\"number_of_reviews\", col(\"number_of_reviews\").cast(IntegerType())) \\\n",
    "    .withColumn(\"price\", col(\"price\").cast(FloatType())) \\\n",
    "    .withColumn(\"minimum_nights\", col(\"minimum_nights\").cast(IntegerType())) \\\n",
    "    .withColumn(\"maximum_nights\", col(\"maximum_nights\").cast(IntegerType())) \\\n",
    "    .withColumn(\"property_type\", col(\"property_type\").cast(StringType())) \\\n",
    "    .withColumn(\"amenities\", col(\"amenities\").cast(StringType())) \\\n",
    "    .withColumn(\"accommodates\", col(\"accommodates\").cast(IntegerType())) \\\n",
    "    .withColumn(\"beds\", col(\"beds\").cast(IntegerType())) \\\n",
    "\n",
    "print(\"\\nSchema after data type conversion:\")\n",
    "print(listing_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1584e6d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b75df5",
   "metadata": {},
   "source": [
    "### Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bae9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming \n",
    "listing_df_renamed = listing_df\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"id\", \"listing_id\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_rating\", \"rating_score\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_accuracy\", \"accuracy_score\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_cleanliness\", \"cleanliness_score\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_checkin\", \"checkin_score\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_communication\", \"communication_score\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_location\", \"location_score\")\n",
    "listing_df_renamed = listing_df_renamed.withColumnRenamed(\"review_scores_value\", \"value_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e82057",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "861be339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import trim \n",
    "listing_df_clean = listing_df_renamed\n",
    "\n",
    "# Handle negative or zero prices\n",
    "listing_df_clean = listing_df_clean.filter(col(\"price\") > 10) \n",
    "\n",
    "# Berlin coordinate bounds validation\n",
    "listing_df_clean = listing_df_clean.filter(\n",
    "    (col(\"latitude\").between(52.3, 52.7)) &   # Berlin latitude range\n",
    "    (col(\"longitude\").between(13.0, 13.8))    # Berlin longitude range\n",
    ")\n",
    "\n",
    "# Review scores should be between 0-5\n",
    "review_cols = [\"rating_score\", \"accuracy_score\", \"cleanliness_score\", \n",
    "               \"checkin_score\", \"communication_score\", \"location_score\", \"value_score\"]\n",
    "\n",
    "for col_name in review_cols:\n",
    "    listing_df_clean = listing_df_clean.withColumn(\n",
    "        col_name,\n",
    "        when((col(col_name) >= 0) & (col(col_name) <= 5), col(col_name))\n",
    "        .otherwise(None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e0f53",
   "metadata": {},
   "source": [
    "### Extend Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2319ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_df_grouped = listing_df_clean\n",
    "\n",
    "# Property type cleansing   \n",
    "from pyspark.sql.functions import when, col, regexp_extract\n",
    "\n",
    "# Level 1: Broad Property Categories\n",
    "listing_df_grouped = listing_df_grouped.withColumn(\"property_category\",\n",
    "    when(col(\"property_type\").rlike(\"(?i)entire\"), \"Entire Property\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)private room\"), \"Private Room\")  \n",
    "    .when(col(\"property_type\").rlike(\"(?i)shared room\"), \"Shared Room\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)room in\"), \"Hotel/Hostel Room\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "\n",
    "# Level 2: Property Type (Housing vs Commercial)\n",
    "listing_df_grouped = listing_df_grouped.withColumn(\"accommodation_type\",\n",
    "    when(col(\"property_type\").rlike(\"(?i)hotel|hostel|aparthotel\"), \"Commercial\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)home|house|apartment|condo|villa|cabin|cottage|loft\"), \"Residential\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)boat|treehouse|cave|dome|tiny|camper|rv\"), \"Unique/Alternative\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "# Level 3: Specific Property Subtype\n",
    "listing_df_grouped = listing_df_grouped.withColumn(\"property_subtype\",\n",
    "    when(col(\"property_type\").rlike(\"(?i)condo\"), \"Condo/Apartment\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)house|home\"), \"House\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)villa|mansion\"), \"Luxury\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)hotel\"), \"Hotel\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)hostel\"), \"Hostel\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)boat|houseboat\"), \"Watercraft\")\n",
    "    .when(col(\"property_type\").rlike(\"(?i)treehouse|cave|dome|tiny\"), \"Unique\")\n",
    "    .otherwise(\"Standard\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85ae05ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9180"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_df_final = listing_df_grouped\n",
    "\n",
    "listing_df_final.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Berlinbnb (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
